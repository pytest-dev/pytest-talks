{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advanced py.test Fixtures\n",
    "\n",
    "```\n",
    "Author: Floris Bruynooghe - 2014\n",
    "Email: flub@devork.be \n",
    "Touchup: Ronny Pfannschmidt - 2019\n",
    "Email: rpfannsc@redhat.com\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Fixtures are powerful:\n",
    "\n",
    "- Dependency Injection\n",
    "- Isolated\n",
    "- Composable\n",
    "\n",
    "Assuming you know:\n",
    "- pytest\n",
    "- basic fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "\n",
    "- floris: Been using and contributing to py.test for a few years\n",
    "- Use at own risk\n",
    "- Some patterns we use in ~70k source\n",
    "- Some from pytest-django\n",
    "- Some made up stuff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Basics\n",
    "\n",
    "You should know this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_simple_fixture_in_class.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_simple_fixture_in_class.py\n",
    "\n",
    "import pytest\n",
    "  \n",
    "@pytest.fixture\n",
    "def foo():\n",
    "    return 42\n",
    "  \n",
    "def test_foo(foo):\n",
    "    assert foo == 42\n",
    "\n",
    "\n",
    "class TestBar:\n",
    "  \n",
    "    @pytest.fixture\n",
    "    def bar(self, request):\n",
    "        print(\"\\nSetup of fixture bar\")\n",
    "        yield 7\n",
    "        print(\"\\nTeardown of fixture bar\")\n",
    "\n",
    "    def test_bar(self, foo, bar):\n",
    "        assert foo != bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.7.3, pytest-5.0.0, py-1.8.0, pluggy-0.12.0 -- /home/rpfannsc/Projects/pytest-dev/pytest-talks/.env/bin/python3.7\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/rpfannsc/Projects/pytest-dev/pytest-talks/talks, inifile: pytest.ini\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "test_simple_fixture_in_class.py::test_foo \u001b[32mPASSED\u001b[0m\n",
      "test_simple_fixture_in_class.py::TestBar::test_bar \n",
      "Setup of fixture bar\n",
      "\u001b[32mPASSED\u001b[0m\n",
      "Teardown of fixture bar\n",
      "\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 2 passed in 0.03 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_simple_fixture_in_class.py -sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Dependency Injection!\n",
    "- Hope you know this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Caching fixtures\n",
    "\n",
    "* Fixture decorator has scope argument\n",
    "* Available scopes: function, class, module, session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_simple_scope_cache.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_simple_scope_cache.py\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture(scope='session')\n",
    "def foo(request):\n",
    "    print('\\nsession setup')\n",
    "    yield foo\n",
    "    print('\\nsession finalizer')\n",
    "  \n",
    "\n",
    "@pytest.fixture(scope='function')\n",
    "def bar(request):\n",
    "    print('\\nfuntion setup')\n",
    "    yield \"bar\"\n",
    "    print('\\nfunction finalizer')\n",
    "\n",
    "    \n",
    "def test_one(foo, bar):\n",
    "    pass\n",
    "  \n",
    "def test_two(foo, bar):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.7.3, pytest-5.0.0, py-1.8.0, pluggy-0.12.0 -- /home/rpfannsc/Projects/pytest-dev/pytest-talks/.env/bin/python3.7\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/rpfannsc/Projects/pytest-dev/pytest-talks/talks, inifile: pytest.ini\n",
      "collected 2 items                                                              \u001b[0m\n",
      "\n",
      "test_simple_scope_cache.py::test_one \n",
      "session setup\n",
      "\n",
      "funtion setup\n",
      "\u001b[32mPASSED\u001b[0m\n",
      "function finalizer\n",
      "\n",
      "test_simple_scope_cache.py::test_two \n",
      "funtion setup\n",
      "\u001b[32mPASSED\u001b[0m\n",
      "function finalizer\n",
      "\n",
      "session finalizer\n",
      "\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 2 passed in 0.03 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! py.test test_simple_scope_cache.py -s -v "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "\n",
    "- session only setup once\n",
    "- fuction twice\n",
    "- `-s~` does not capture stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interdependent fixtures\n",
    "\n",
    "Fixture can use fixtures too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "@pytest.fixture(scope='session')\n",
    "def db_conn():\n",
    "    return ...\n",
    "  \n",
    "@pytest.fixture(scope='module')\n",
    "def db_table(request, db_conn):\n",
    "    table = create_table(db_conn, 'foo')\n",
    "    yield table  \n",
    "    drop_table(db_conn, table)\n",
    "    \n",
    "def test_bar(db_table):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Fixtures can depend on each other\n",
    "- Functional test example\n",
    "- Request is just a built-in fixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Skip/fail in fixture\n",
    "\n",
    "Fixtures can trigger skipping/failing of all dependent tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "import redis\n",
    "\n",
    "@pytest.fixture(scope='session')\n",
    "def redis_client():\n",
    "    servers = ['localhost', 'venera.clockhouse']\n",
    "    for hostname in servers:\n",
    "        try:\n",
    "            return redis.StrictRedis(hostname)\n",
    "        except redis.ConnectionError:\n",
    "            continue\n",
    "    else:\n",
    "        pytest.skip('No Redis server found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "\n",
    "- this will respect scope\n",
    "- also pytest.fail()\n",
    "- .fail() and .skip() just raise an exception\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Marks\n",
    "\n",
    "Rember tests can be marked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_have_markers.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_have_markers.py\n",
    "import pytest\n",
    "\n",
    "@pytest.mark.mymarker\n",
    "@pytest.mark.other_marker\n",
    "def test_something():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Run tests based on markers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\r\n",
      "platform linux -- Python 3.7.3, pytest-5.0.0, py-1.8.0, pluggy-0.12.0\r\n",
      "rootdir: /home/rpfannsc/Projects/pytest-dev/pytest-talks/talks, inifile: pytest.ini\r\n",
      "\u001b[1mcollecting ... \u001b[0m\u001b[1m\r",
      "collected 1 item / 1 deselected                                                \u001b[0m\r\n",
      "\r\n",
      "\u001b[33m\u001b[1m========================= 1 deselected in 0.02 seconds =========================\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "! pytest -m \"not mymarker\" test_have_markers.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Make them known:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pytest.ini\n"
     ]
    }
   ],
   "source": [
    "%%writefile pytest.ini\n",
    "[pytest]\n",
    "markers =\n",
    "  mymarker: a custom marker\n",
    "  other_marker: another marker\n",
    "  linux: helper marker for checking the platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- mark a test\n",
    "- run test from command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using Marks from Fixtures\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def mongo_client(request):\n",
    "    marker = request.node.get_marker('mongo_db') or pytest.mark.not_used\n",
    "    def apifun(db = 'TestDB'):\n",
    "        return db\n",
    "    db = apifun(*marker.args, **marker.kwargs)\n",
    "    return pymongo.MongoClient('127.0.0.1/{}'.format(db))\n",
    "  \n",
    "@pytest.mark.mongo_db('Users')\n",
    "def test_something(mongo_client):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Use a mark as a parameter to a fixture\n",
    "- Maybe consider re-designing the fixture\n",
    "- apifun current hack to get python argument parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Autouse fixtues\n",
    "\n",
    "Setup/teardown without explicit request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_markers_conditional_skip_autouse.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_markers_conditional_skip_autouse.py\n",
    "import pytest\n",
    "import platform\n",
    "import attr\n",
    "\n",
    "@attr.s\n",
    "class MemSizes:\n",
    "    stack = attr.ib(default=42)\n",
    "\n",
    "\n",
    "@pytest.mark.linux\n",
    "def test_mem_stack():\n",
    "    assert MemSizes().stack == 42\n",
    "  \n",
    "@pytest.fixture(autouse=True)\n",
    "def _platform_skip(request):\n",
    "    marker = request.node.get_closest_marker('linux')\n",
    "    if marker and platform.system() != 'Linux':\n",
    "        pytest.skip('N/A on {}'.format(platform.system()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.7.3, pytest-5.0.0, py-1.8.0, pluggy-0.12.0\n",
      "rootdir: /home/rpfannsc/Projects/pytest-dev/pytest-talks/talks, inifile: pytest.ini\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "test_markers_conditional_skip_autouse.py \u001b[32m.\u001b[0m\u001b[36m                               [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 1 passed in 0.03 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest test_markers_conditional_skip_autouse.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- An autouse fixture to detect the mark\n",
    "- Autouse fixture invoked before each test\n",
    "- Autouse also useful without marks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parametrizing fixtures\n",
    "\n",
    "- Individual fixtures can be paremeterised\n",
    "- Multiple parameterised fixtures combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting combinatoric_parameters.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile combinatoric_parameters.py\n",
    "import pytest\n",
    "import socket\n",
    "\n",
    "\n",
    "def create_db_uri(kind):\n",
    "    return kind + \"://localhost\"\n",
    "\n",
    "    \n",
    "@pytest.fixture(params=['ora', 'pg', 'sqlite'])\n",
    "def dburi(request):\n",
    "    return create_db_uri(request.param)\n",
    "  \n",
    "@pytest.fixture(params=['ipv4', 'ipv6'])\n",
    "def addr_family(request):\n",
    "    return socket.AF_INET if request.param == 'ipv4' else socket.AF_INET6\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_combinatoric_parameters.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_combinatoric_parameters.py\n",
    "\n",
    "import attr\n",
    "import socket\n",
    "\n",
    "@attr.s\n",
    "class MyObj:\n",
    "    uri = attr.ib()\n",
    "    addr_family = attr.ib(default=socket.AF_INET)\n",
    "    \n",
    "    def it_works(self):\n",
    "        return True\n",
    "    transaction_works = it_works\n",
    "\n",
    "def test_txn(dburi):\n",
    "    inst = MyObj(dburi)\n",
    "    assert inst.transaction_works()\n",
    "\n",
    "    \n",
    "def test_conn(dburi, addr_family):\n",
    "    inst = MyObj(dburi, addr_family)\n",
    "    assert inst.it_works()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.7.3, pytest-5.0.0, py-1.8.0, pluggy-0.12.0 -- /home/rpfannsc/Projects/pytest-dev/pytest-talks/.env/bin/python3.7\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/rpfannsc/Projects/pytest-dev/pytest-talks/talks, inifile: pytest.ini\n",
      "collected 9 items                                                              \u001b[0m\n",
      "\n",
      "test_combinatoric_parameters.py::test_txn[ora] \u001b[32mPASSED\u001b[0m\u001b[36m                    [ 11%]\u001b[0m\n",
      "test_combinatoric_parameters.py::test_txn[pg] \u001b[32mPASSED\u001b[0m\u001b[36m                     [ 22%]\u001b[0m\n",
      "test_combinatoric_parameters.py::test_txn[sqlite] \u001b[32mPASSED\u001b[0m\u001b[36m                 [ 33%]\u001b[0m\n",
      "test_combinatoric_parameters.py::test_conn[ora-ipv4] \u001b[32mPASSED\u001b[0m\u001b[36m              [ 44%]\u001b[0m\n",
      "test_combinatoric_parameters.py::test_conn[ora-ipv6] \u001b[32mPASSED\u001b[0m\u001b[36m              [ 55%]\u001b[0m\n",
      "test_combinatoric_parameters.py::test_conn[pg-ipv4] \u001b[32mPASSED\u001b[0m\u001b[36m               [ 66%]\u001b[0m\n",
      "test_combinatoric_parameters.py::test_conn[pg-ipv6] \u001b[32mPASSED\u001b[0m\u001b[36m               [ 77%]\u001b[0m\n",
      "test_combinatoric_parameters.py::test_conn[sqlite-ipv4] \u001b[32mPASSED\u001b[0m\u001b[36m           [ 88%]\u001b[0m\n",
      "test_combinatoric_parameters.py::test_conn[sqlite-ipv6] \u001b[32mPASSED\u001b[0m\u001b[36m           [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m=========================== 9 passed in 0.04 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!PYTHONPATH=. pytest test_combinatoric_parameters.py -p combinatoric_parameters -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "\n",
    "- Powerful, combinatory\n",
    "- Functional test example\n",
    "- This will execute 6 versions of test_func\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Skipping Parameters\n",
    "\n",
    "Skipping can be done on a parameter level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "try:\n",
    "    import cx_Oracle as ora\n",
    "except ImportError:\n",
    "    ora = None\n",
    "  \n",
    "\n",
    "needs_ora = pytest.mark.skipif(ora is None, reason='No Oracle installed')\n",
    "  \n",
    "@pytest.fixture(params=[\n",
    "    'pg',\n",
    "    pytest.param(ora, marks=needs_ora),\n",
    "])\n",
    "def dburi(request):\n",
    "    return create_db_uri(request.param)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Marks can be assigned to vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Accessing Fixture Info\n",
    "\n",
    "Find out what other fixtures are requested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "  \n",
    "@pytest.fixture\n",
    "def db(request):\n",
    "    if 'transactional_db' in request.fixturenames:\n",
    "        pytest.fail('Conflicting fixtures')\n",
    "    return no_transactions_db()\n",
    "  \n",
    "@pytest.fixture\n",
    "def transactional_db(request):\n",
    "    if 'db' in request.fixturenames:\n",
    "        pytest.fail('Conflicting fixtures')\n",
    "    return transactional_db()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Mutual exclusive fixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plugins and Hooks\n",
    "\n",
    "```\n",
    "myproj/\n",
    "+- myproj/\n",
    "|  +- __init__.py\n",
    "|  +- models.py\n",
    "+- tests/\n",
    "   +- contest.py\n",
    "   +- test_models.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A few common hooks:\n",
    "\n",
    "* `pytest_addoption(parser)`\n",
    "* `pytest_ignore_collect(path, config)`\n",
    "* `pytest_sessionstart(session)`\n",
    "* `pytest_sessionfinish(session, exitstatus)`\n",
    "* `pytest_assertrepr_compare(config, op, left, right)`\n",
    "\n",
    "See hookspec for full list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "\n",
    "- `conftest.py` is a plugin\n",
    "- For advanced test suites you end up writing your own plugin.\n",
    "- Source in hookspec.py or in docs\n",
    "- Arguments are optional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using commandline options\n",
    "\n",
    "New options an be accessed from fixtures and tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#conftest.py\n",
    "import pytest\n",
    "def pytest_addoption(parser):\n",
    "    parser.addoption('--ci', action='store_true',\n",
    "                     help='Indicate tests are run on CI server')\n",
    "@pytest.fixture\n",
    "def fix(request):\n",
    "    ci = request.config.getoption('ci')\n",
    "\n",
    "# Test module\n",
    "def test_foo(pytestconfig):\n",
    "    ci = pytestconfig.getoption('ci')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "\n",
    "- You can add your own command line options\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## skip or fail\n",
    "\n",
    "Skipping not allowed on CI server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "@pytest.fixture(scope='session')\n",
    "def redis_client(request):\n",
    "    servers = ['localhost', 'venera.clockhouse']\n",
    "    for hostname in servers:\n",
    "        try:\n",
    "            return redis.StrictRedis(hostname)\n",
    "        except redis.ConnectionError:\n",
    "            continue\n",
    "        else:\n",
    "            if request.config.getoption('ci'):\n",
    "                pytest.fail('No Redis server found')\n",
    "            else:\n",
    "                pytest.skip('No Redis server found')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Also mention to pass server loc via cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions?\n",
    "\n",
    "Thanks for listening!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
